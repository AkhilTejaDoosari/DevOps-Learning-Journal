# **12. Essential Utilities — Compression, Archiving, Search, and More**
> Bonus utilities every DevOps engineer should know.

---

## Table of Contents
- [1. Why These Utilities Matter](#1-why-these-utilities-matter)
- [2. File Compression with gzip and bzip2](#2-file-compression-with-gzip-and-bzip2)
- [3. Archiving with tar](#3-archiving-with-tar)
- [4. Creating Backups](#4-creating-backups)
- [5. Finding Files with find](#5-finding-files-with-find)
- [6. Locating Files Quickly](#6-locating-files-quickly)
- [7. Background Jobs Management](#7-background-jobs-management)
- [8. Disk Usage Analysis](#8-disk-usage-analysis)
- [9. Watching Commands](#9-watching-commands)
- [10. File Timestamps](#10-file-timestamps)
- [11. Symbolic and Hard Links Deep Dive](#11-symbolic-and-hard-links-deep-dive)
- [12. xargs: Command Builder](#12-xargs-command-builder)
- [13. Screen and tmux: Terminal Multiplexers](#13-screen-and-tmux-terminal-multiplexers)
- [14. System Resource Limits](#14-system-resource-limits)
- [15. Checksums and Verification](#15-checksums-and-verification)
- [16. Real-World Scenarios](#16-real-world-scenarios)
- [17. Commands Reference](#17-commands-reference)
- [18. Quick Reference](#18-quick-reference)

---

<details>
<summary><strong>1. Why These Utilities Matter</strong></summary>

<div style="margin-left: 16px; margin-right: 16px; margin-top: 8px; margin-bottom: 8px;">

These utilities aren't used daily, but when you need them, they're essential.

Whether it's:
- Creating compressed backups
- Finding files across the system
- Managing long-running terminal sessions
- Verifying file integrity
- Monitoring command output continuously

Understanding these tools means:
- you can create and extract archives confidently
- you can find files anywhere on the system
- you can maintain persistent sessions over SSH
- you can automate complex file operations

This is your Swiss Army knife of Linux utilities.

</div>

</details>

---

<details>
<summary><strong>2. File Compression with gzip and bzip2</strong></summary>

<div style="margin-left: 16px; margin-right: 16px; margin-top: 8px; margin-bottom: 8px;">

### UTIL-001 — gzip Compression

**gzip** compresses files to save space.

**Compress file:**
```bash copy
gzip file.txt
# Creates: file.txt.gz (original removed)
```

**Keep original:**
```bash copy
gzip -k file.txt
# Creates: file.txt.gz (original kept)
```

**Decompress:**
```bash copy
gunzip file.txt.gz
# OR
gzip -d file.txt.gz
```

**View compressed file without extracting:**
```bash copy
zcat file.txt.gz
zless file.txt.gz
zgrep "pattern" file.txt.gz
```

**Compression levels:**
```bash copy
gzip -1 file.txt    # Fastest (least compression)
gzip -9 file.txt    # Best compression (slowest)
gzip file.txt       # Default (level 6)
```

---

### UTIL-002 — bzip2 Compression

**bzip2** offers better compression than gzip but slower.

**Compress:**
```bash copy
bzip2 file.txt
# Creates: file.txt.bz2
```

**Decompress:**
```bash copy
bunzip2 file.txt.bz2
# OR
bzip2 -d file.txt.bz2
```

**Keep original:**
```bash copy
bzip2 -k file.txt
```

---

### UTIL-003 — xz Compression

**xz** provides even better compression.

**Compress:**
```bash copy
xz file.txt
# Creates: file.txt.xz
```

**Decompress:**
```bash copy
unxz file.txt.xz
# OR
xz -d file.txt.xz
```

**Comparison:**

| Tool | Speed | Compression Ratio | Common Usage |
|------|-------|-------------------|--------------|
| gzip | Fast | Good | Most common, default |
| bzip2 | Medium | Better | When space is critical |
| xz | Slow | Best | Maximum compression |

</div>

</details>

---

<details>
<summary><strong>3. Archiving with tar</strong></summary>

<div style="margin-left: 16px; margin-right: 16px; margin-top: 8px; margin-bottom: 8px;">

### UTIL-004 — tar Basics

**tar** (tape archive) combines multiple files into one.

**Create archive:**
```bash copy
tar -cvf archive.tar directory/
# -c: create
# -v: verbose
# -f: filename
```

**Extract archive:**
```bash copy
tar -xvf archive.tar
# -x: extract
```

**List contents:**
```bash copy
tar -tvf archive.tar
# -t: list
```

**Extract to specific directory:**
```bash copy
tar -xvf archive.tar -C /destination/path/
```

---

### UTIL-005 — tar with Compression

**Create compressed archives:**

**gzip (most common):**
```bash copy
tar -czf archive.tar.gz directory/
# -z: gzip compression
```

**bzip2:**
```bash copy
tar -cjf archive.tar.bz2 directory/
# -j: bzip2 compression
```

**xz:**
```bash copy
tar -cJf archive.tar.xz directory/
# -J: xz compression
```

**Extract compressed archives:**
```bash copy
tar -xzf archive.tar.gz      # gzip
tar -xjf archive.tar.bz2     # bzip2
tar -xJf archive.tar.xz      # xz
```

**Modern tar auto-detects compression:**
```bash copy
tar -xf archive.tar.gz       # automatically detects gzip
tar -xf archive.tar.bz2      # automatically detects bzip2
```

---

### UTIL-006 — Practical tar Examples

**Backup home directory:**
```bash copy
tar -czf home_backup_$(date +%Y%m%d).tar.gz ~
```

**Backup excluding certain files:**
```bash copy
tar -czf backup.tar.gz --exclude='*.log' --exclude='node_modules' /var/www
```

**Extract single file from archive:**
```bash copy
tar -xzf archive.tar.gz path/to/file.txt
```

**Append files to existing archive:**
```bash copy
tar -rvf archive.tar newfile.txt
# Note: Can't append to compressed archives
```

**Create archive and show progress:**
```bash copy
tar -czf archive.tar.gz directory/ --checkpoint=1000 --checkpoint-action=dot
```

</div>

</details>

---

<details>
<summary><strong>4. Creating Backups</strong></summary>

<div style="margin-left: 16px; margin-right: 16px; margin-top: 8px; margin-bottom: 8px;">

### UTIL-007 — Backup Strategies

**Daily backup script:**
```bash copy
#!/bin/bash
BACKUP_DIR="/backups"
DATE=$(date +%Y%m%d)
tar -czf $BACKUP_DIR/backup_$DATE.tar.gz /var/www /etc/nginx
```

**Incremental backups:**
```bash copy
# Full backup
tar -czf full_backup.tar.gz /data

# Incremental (only changed files)
tar -czf incremental_$(date +%Y%m%d).tar.gz --listed-incremental=snapshot.file /data
```

**Backup with exclusions:**
```bash copy
tar -czf backup.tar.gz \
  --exclude='*.log' \
  --exclude='*.tmp' \
  --exclude='node_modules' \
  /var/www
```

**Backup and send to remote:**
```bash copy
tar -czf - /var/www | ssh user@remote "cat > /backups/backup.tar.gz"
```

</div>

</details>

---

<details>
<summary><strong>5. Finding Files with find</strong></summary>

<div style="margin-left: 16px; margin-right: 16px; margin-top: 8px; margin-bottom: 8px;">

### UTIL-008 — find Command Basics

**find** searches for files by name, size, time, permissions, etc.

**Find by name:**
```bash copy
find /path -name "filename.txt"
```

**Case-insensitive:**
```bash copy
find /path -iname "filename.txt"
```

**Find by pattern:**
```bash copy
find /var/log -name "*.log"
```

**Find directories only:**
```bash copy
find /path -type d
```

**Find files only:**
```bash copy
find /path -type f
```

---

### UTIL-009 — find by Size

**Find large files:**
```bash copy
find / -type f -size +100M
# Files larger than 100MB
```

**Find small files:**
```bash copy
find /path -type f -size -1M
# Files smaller than 1MB
```

**Size units:**
- `c` — bytes
- `k` — kilobytes
- `M` — megabytes
- `G` — gigabytes

---

### UTIL-010 — find by Time

**Modified in last 7 days:**
```bash copy
find /path -mtime -7
```

**Modified more than 30 days ago:**
```bash copy
find /path -mtime +30
```

**Accessed in last hour:**
```bash copy
find /path -amin -60
```

**Time options:**
- `-mtime` — modification time (days)
- `-atime` — access time (days)
- `-ctime` — change time (days)
- `-mmin` — modification time (minutes)
- `-amin` — access time (minutes)

---

### UTIL-011 — find by Permissions

**Find files with specific permissions:**
```bash copy
find /path -perm 644
```

**Find files writable by others:**
```bash copy
find /path -perm -002
```

**Find SUID files:**
```bash copy
find / -perm -4000
```

---

### UTIL-012 — find with Actions

**Delete found files:**
```bash copy
find /tmp -name "*.tmp" -delete
```

**Execute command on found files:**
```bash copy
find /var/log -name "*.log" -exec gzip {} \;
```

**Execute with confirmation:**
```bash copy
find /path -name "*.bak" -ok rm {} \;
```

**Multiple files per command (more efficient):**
```bash copy
find /path -name "*.txt" -exec grep "error" {} +
```

---

### UTIL-013 — Practical find Examples

**Find and list large files:**
```bash copy
find / -type f -size +100M -exec ls -lh {} \; 2>/dev/null
```

**Find old log files and delete:**
```bash copy
find /var/log -name "*.log" -mtime +30 -delete
```

**Find files modified today:**
```bash copy
find /home -type f -mtime 0
```

**Find empty files:**
```bash copy
find /path -type f -empty
```

**Find empty directories:**
```bash copy
find /path -type d -empty
```

**Find and compress old files:**
```bash copy
find /data -name "*.txt" -mtime +90 -exec gzip {} \;
```

</div>

</details>

---

<details>
<summary><strong>6. Locating Files Quickly</strong></summary>

<div style="margin-left: 16px; margin-right: 16px; margin-top: 8px; margin-bottom: 8px;">

### UTIL-014 — locate Command

**locate** uses a pre-built database for fast searches.

**Find file:**
```bash copy
locate filename.txt
```

**Case-insensitive:**
```bash copy
locate -i filename.txt
```

**Limit results:**
```bash copy
locate -n 10 filename
```

**Update database (requires sudo):**
```bash copy
sudo updatedb
```

**Why locate is fast:**
Searches a database (`/var/lib/mlocate/mlocate.db`), not the entire filesystem.

**Limitation:**
Database updated daily (cron job), so recently created files won't appear until next update.

---

### UTIL-015 — which vs whereis

**which** shows path of executable in PATH:
```bash copy
which python3
# Output: /usr/bin/python3
```

**whereis** shows binary, source, and man page:
```bash copy
whereis python3
# Output: python3: /usr/bin/python3 /usr/share/man/man1/python3.1.gz
```

</div>

</details>

---

<details>
<summary><strong>7. Background Jobs Management</strong></summary>

<div style="margin-left: 16px; margin-right: 16px; margin-top: 8px; margin-bottom: 8px;">

### UTIL-016 — Running Jobs in Background

**Run command in background:**
```bash copy
long_running_command &
# Output: [1] 12345 (job number and PID)
```

**Background with nohup (survives logout):**
```bash copy
nohup long_running_command &
```

**Redirect output:**
```bash copy
nohup python script.py > output.log 2>&1 &
```

---

### UTIL-017 — Managing Jobs

**List jobs:**
```bash copy
jobs
# Output: [1]+ Running    sleep 100 &
```

**Bring job to foreground:**
```bash copy
fg %1
# Brings job 1 to foreground
```

**Send job to background:**
```bash copy
bg %1
# Continues job 1 in background
```

**Suspend current job:**
```bash copy
Ctrl+Z
# Stops current foreground job
```

**Resume in background:**
```bash copy
bg
```

**Kill background job:**
```bash copy
kill %1
```

---

### UTIL-018 — disown

**Detach job from shell:**
```bash copy
long_running_command &
disown
```

Now the job won't be killed when you log out.

**Why use disown:**
- For processes started without `nohup`
- Need to detach after starting

</div>

</details>

---

<details>
<summary><strong>8. Disk Usage Analysis</strong></summary>

<div style="margin-left: 16px; margin-right: 16px; margin-top: 8px; margin-bottom: 8px;">

### UTIL-019 — Advanced du Usage

**Disk usage by directory:**
```bash copy
du -h /var
```

**Sort by size:**
```bash copy
du -h /var | sort -rh | head -20
```

**One level deep:**
```bash copy
du -h --max-depth=1 /var
```

**Total size only:**
```bash copy
du -sh /var/log
```

**Exclude patterns:**
```bash copy
du -h --exclude="*.log" /var
```

---

### UTIL-020 — ncdu (Interactive)

**ncdu** provides interactive disk usage exploration.

**Installation:**
```bash copy
sudo apt install ncdu    # Debian/Ubuntu
sudo dnf install ncdu    # RHEL/Fedora
```

**Usage:**
```bash copy
ncdu /var
```

**Navigation:**
- Arrow keys: navigate
- Enter: drill down
- `d`: delete files
- `q`: quit

</div>

</details>

---

<details>
<summary><strong>9. Watching Commands</strong></summary>

<div style="margin-left: 16px; margin-right: 16px; margin-top: 8px; margin-bottom: 8px;">

### UTIL-021 — watch Command

**watch** runs a command repeatedly and shows output.

**Basic usage:**
```bash copy
watch df -h
# Updates every 2 seconds
```

**Custom interval:**
```bash copy
watch -n 5 free -h
# Updates every 5 seconds
```

**Highlight differences:**
```bash copy
watch -d free -h
```

**No title:**
```bash copy
watch -t date
```

**Use cases:**
- Monitor disk space
- Watch process list
- Track file changes
- Monitor network stats

**Examples:**
```bash copy
watch -n 1 'ps aux | grep nginx'
watch -n 5 'netstat -tulpn | grep :80'
watch -n 10 'ls -lh /var/log/nginx/access.log'
```

</div>

</details>

---

<details>
<summary><strong>10. File Timestamps</strong></summary>

<div style="margin-left: 16px; margin-right: 16px; margin-top: 8px; margin-bottom: 8px;">

### UTIL-022 — Understanding Timestamps

Every file has three timestamps:

**atime (Access Time):**
Last time file was read.

**mtime (Modification Time):**
Last time file content was modified.

**ctime (Change Time):**
Last time file metadata was changed (permissions, ownership).

**View timestamps:**
```bash copy
stat filename
```

**Output shows:**
```
Access: 2025-01-15 10:00:00
Modify: 2025-01-15 09:00:00
Change: 2025-01-15 09:00:00
```

---

### UTIL-023 — touch for Timestamps

**Update timestamps to now:**
```bash copy
touch filename
```

**Update only access time:**
```bash copy
touch -a filename
```

**Update only modification time:**
```bash copy
touch -m filename
```

**Set specific timestamp:**
```bash copy
touch -t 202501151000 filename
# Format: YYYYMMDDhhmm
```

**Copy timestamp from another file:**
```bash copy
touch -r reference_file target_file
```

</div>

</details>

---

<details>
<summary><strong>11. Symbolic and Hard Links Deep Dive</strong></summary>

<div style="margin-left: 16px; margin-right: 16px; margin-top: 8px; margin-bottom: 8px;">

### UTIL-024 — Link Internals

**Viewing inode numbers:**
```bash copy
ls -li
```

**Output:**
```
12345678 -rw-r--r-- 2 user group 1024 Jan 15 10:00 original.txt
12345678 -rw-r--r-- 2 user group 1024 Jan 15 10:00 hardlink.txt
87654321 lrwxrwxrwx 1 user group   12 Jan 15 10:01 symlink.txt -> original.txt
```

Notice:
- Hard link has same inode (12345678)
- Symlink has different inode (87654321)

---

### UTIL-025 — Finding Links

**Find all hard links to a file:**
```bash copy
find / -inum 12345678
```

**Find broken symbolic links:**
```bash copy
find /path -type l -xtype l
```

**Find symbolic links pointing to specific file:**
```bash copy
find / -lname original.txt
```

</div>

</details>

---

<details>
<summary><strong>12. xargs: Command Builder</strong></summary>

<div style="margin-left: 16px; margin-right: 16px; margin-top: 8px; margin-bottom: 8px;">

### UTIL-026 — xargs Basics

**xargs** builds and executes commands from standard input.

**Basic usage:**
```bash copy
find /path -name "*.txt" | xargs rm
# Deletes all .txt files
```

**Why xargs?**
Many commands don't accept stdin. xargs converts stdin to arguments.

**Print what would be executed:**
```bash copy
find /path -name "*.txt" | xargs -p rm
# -p: prompt before executing
```

**Handle spaces in filenames:**
```bash copy
find /path -name "*.txt" -print0 | xargs -0 rm
```

---

### UTIL-027 — xargs Advanced

**Process N items at a time:**
```bash copy
find /path -name "*.log" | xargs -n 1 gzip
# Processes one file at a time
```

**Parallel execution:**
```bash copy
find /path -name "*.txt" | xargs -P 4 -n 1 process_file.sh
# Uses 4 parallel processes
```

**Custom delimiter:**
```bash copy
echo "file1:file2:file3" | xargs -d: echo
```

**Replace string:**
```bash copy
cat files.txt | xargs -I {} cp {} /backup/
# {} is replaced with each input line
```

---

### UTIL-028 — Practical xargs Examples

**Compress multiple files:**
```bash copy
find /data -name "*.log" -mtime +30 | xargs gzip
```

**Download multiple URLs:**
```bash copy
cat urls.txt | xargs -n 1 -P 5 wget
```

**Delete files from list:**
```bash copy
cat files_to_delete.txt | xargs rm
```

**Change ownership:**
```bash copy
find /var/www -user olduser | xargs chown newuser:newgroup
```

</div>

</details>

---

<details>
<summary><strong>13. Screen and tmux: Terminal Multiplexers</strong></summary>

<div style="margin-left: 16px; margin-right: 16px; margin-top: 8px; margin-bottom: 8px;">

### UTIL-029 — Why Terminal Multiplexers?

**Problem:**
SSH disconnects kill your running processes.

**Solution:**
Terminal multiplexers (screen, tmux) keep sessions alive.

**Use cases:**
- Long-running deployments
- Remote server maintenance
- Multiple terminal panes
- Persistent sessions

---

### UTIL-030 — screen Basics

**Start new session:**
```bash copy
screen
```

**Start named session:**
```bash copy
screen -S mysession
```

**Detach from session:**
```
Ctrl+A then D
```

**List sessions:**
```bash copy
screen -ls
```

**Reattach to session:**
```bash copy
screen -r mysession
```

**Kill session:**
```bash copy
screen -X -S mysession quit
```

---

### UTIL-031 — tmux Basics

**tmux** is modern alternative to screen.

**Start new session:**
```bash copy
tmux
```

**Start named session:**
```bash copy
tmux new -s mysession
```

**Detach:**
```
Ctrl+B then D
```

**List sessions:**
```bash copy
tmux ls
```

**Attach to session:**
```bash copy
tmux attach -t mysession
```

**Kill session:**
```bash copy
tmux kill-session -t mysession
```

---

### UTIL-032 — tmux Panes and Windows

**Split horizontally:**
```
Ctrl+B then "
```

**Split vertically:**
```
Ctrl+B then %
```

**Navigate panes:**
```
Ctrl+B then arrow keys
```

**Create new window:**
```
Ctrl+B then C
```

**Switch windows:**
```
Ctrl+B then 0-9
```

**Why tmux over screen:**
- More active development
- Better pane management
- Easier configuration
- More features

</div>

</details>

---

<details>
<summary><strong>14. System Resource Limits</strong></summary>

<div style="margin-left: 16px; margin-right: 16px; margin-top: 8px; margin-bottom: 8px;">

### UTIL-033 — ulimit

**ulimit** controls resource limits for processes.

**View current limits:**
```bash copy
ulimit -a
```

**File descriptor limit:**
```bash copy
ulimit -n
# Default often 1024
```

**Increase file descriptor limit:**
```bash copy
ulimit -n 4096
```

**Maximum processes:**
```bash copy
ulimit -u
```

**Core dump size:**
```bash copy
ulimit -c unlimited
# Enable core dumps
```

**Permanent limits:**
Edit `/etc/security/limits.conf`:
```
username soft nofile 4096
username hard nofile 8192
```

</div>

</details>

---

<details>
<summary><strong>15. Checksums and Verification</strong></summary>

<div style="margin-left: 16px; margin-right: 16px; margin-top: 8px; margin-bottom: 8px;">

### UTIL-034 — File Checksums

**MD5 checksum:**
```bash copy
md5sum file.iso
```

**SHA256 checksum:**
```bash copy
sha256sum file.iso
```

**Verify checksum:**
```bash copy
echo "checksum_value file.iso" | sha256sum -c
```

**Create checksum file:**
```bash copy
sha256sum *.iso > checksums.txt
```

**Verify all:**
```bash copy
sha256sum -c checksums.txt
```

**Why checksums matter:**
- Verify download integrity
- Detect file corruption
- Ensure file hasn't been tampered with

</div>

</details>

---

<details>
<summary><strong>16. Real-World Scenarios</strong></summary>

<div style="margin-left: 16px; margin-right: 16px; margin-top: 8px; margin-bottom: 8px;">

### Scenario 1: Create Compressed Backup

**Symptom:**
Need to backup website directory daily.

**Cause:**
Backup requirement for disaster recovery.

**Fix:**
```bash copy
#!/bin/bash
BACKUP_DIR="/backups"
DATE=$(date +%Y%m%d)
SOURCE="/var/www"

# Create compressed backup
tar -czf $BACKUP_DIR/website_$DATE.tar.gz $SOURCE

# Keep only last 7 days
find $BACKUP_DIR -name "website_*.tar.gz" -mtime +7 -delete
```

**Confirm:**
```bash copy
ls -lh /backups/
# Shows daily backups
```

---

### Scenario 2: Find and Delete Old Log Files

**Symptom:**
Disk filling up with old log files.

**Cause:**
Logs not being cleaned up.

**Fix:**
```bash copy
# Find logs older than 30 days
find /var/log -name "*.log" -mtime +30

# Compress them
find /var/log -name "*.log" -mtime +30 -exec gzip {} \;

# Delete logs older than 90 days
find /var/log -name "*.log.gz" -mtime +90 -delete
```

**Confirm:**
```bash copy
df -h
# Disk usage reduced
```

---

### Scenario 3: Extract Single File from Backup

**Symptom:**
Need to restore one file from backup archive.

**Cause:**
Accidental deletion.

**Fix:**
```bash copy
# List contents
tar -tzf backup.tar.gz | grep config.php

# Extract specific file
tar -xzf backup.tar.gz path/to/config.php
```

**Confirm:**
```bash copy
ls -l path/to/config.php
# File restored
```

---

### Scenario 4: Long-Running Deployment Over SSH

**Symptom:**
Need to run deployment but SSH might disconnect.

**Cause:**
Long-running process, unreliable connection.

**Fix:**
```bash copy
# Start tmux session
tmux new -s deployment

# Run deployment
./deploy.sh

# Detach: Ctrl+B then D

# Logout, come back later
tmux attach -s deployment
```

**Confirm:**
Process continues running even if SSH disconnects.

---

### Scenario 5: Find Large Files Consuming Space

**Symptom:**
Disk full, need to find culprits.

**Cause:**
Unknown large files.

**Fix:**
```bash copy
# Find files > 100MB
find / -type f -size +100M -exec ls -lh {} \; 2>/dev/null | sort -k5 -hr

# OR use du
du -h / 2>/dev/null | sort -rh | head -20

# OR use ncdu interactively
ncdu /
```

**Confirm:**
Identified and removed large unnecessary files.

---

### Scenario 6: Compress All Old Files

**Symptom:**
Need to compress data files older than 90 days.

**Cause:**
Disk space optimization.

**Fix:**
```bash copy
# Find and compress
find /data -name "*.txt" -mtime +90 -exec gzip {} \;

# Verify
find /data -name "*.txt.gz" -mtime +90
```

**Confirm:**
```bash copy
du -sh /data
# Space usage reduced
```

</div>

</details>

---

<details>
<summary><strong>17. Commands Reference</strong></summary>

<div style="margin-left: 16px; margin-right: 16px; margin-top: 8px; margin-bottom: 8px;">

**Compression:**

```bash copy
gzip file.txt   # compress file
```

```bash copy
gunzip file.txt.gz   # decompress
```

```bash copy
gzip -k file.txt   # keep original
```

```bash copy
bzip2 file.txt   # compress with bzip2
```

```bash copy
bunzip2 file.txt.bz2   # decompress bzip2
```

```bash copy
xz file.txt   # compress with xz
```

```bash copy
unxz file.txt.xz   # decompress xz
```

**Archiving:**

```bash copy
tar -cvf archive.tar directory/   # create archive
```

```bash copy
tar -xvf archive.tar   # extract archive
```

```bash copy
tar -tvf archive.tar   # list contents
```

```bash copy
tar -czf archive.tar.gz directory/   # create compressed (gzip)
```

```bash copy
tar -xzf archive.tar.gz   # extract compressed
```

```bash copy
tar -cjf archive.tar.bz2 directory/   # create compressed (bzip2)
```

```bash copy
tar -cJf archive.tar.xz directory/   # create compressed (xz)
```

```bash copy
tar -czf backup.tar.gz --exclude='*.log' /data   # with exclusions
```

**Finding Files:**

```bash copy
find /path -name "filename"   # find by name
```

```bash copy
find /path -iname "filename"   # case-insensitive
```

```bash copy
find /path -type f   # files only
```

```bash copy
find /path -type d   # directories only
```

```bash copy
find /path -size +100M   # files > 100MB
```

```bash copy
find /path -mtime -7   # modified in last 7 days
```

```bash copy
find /path -mtime +30   # modified > 30 days ago
```

```bash copy
find /path -name "*.tmp" -delete   # find and delete
```

```bash copy
find /path -name "*.log" -exec gzip {} \;   # find and compress
```

```bash copy
locate filename   # quick search (uses database)
```

```bash copy
sudo updatedb   # update locate database
```

**Background Jobs:**

```bash copy
command &   # run in background
```

```bash copy
nohup command &   # run and survive logout
```

```bash copy
jobs   # list background jobs
```

```bash copy
fg %1   # bring job 1 to foreground
```

```bash copy
bg %1   # continue job 1 in background
```

```bash copy
disown   # detach job from shell
```

**Disk Usage:**

```bash copy
du -h /path   # disk usage
```

```bash copy
du -sh /path   # total size only
```

```bash copy
du -h --max-depth=1 /path   # one level deep
```

```bash copy
ncdu /path   # interactive disk usage
```

**Watching:**

```bash copy
watch df -h   # watch command (updates every 2s)
```

```bash copy
watch -n 5 free -h   # custom interval (5s)
```

```bash copy
watch -d command   # highlight differences
```

**Timestamps:**

```bash copy
stat filename   # show all timestamps
```

```bash copy
touch filename   # update timestamps to now
```

```bash copy
touch -t 202501151000 filename   # set specific time
```

**xargs:**

```bash copy
find /path -name "*.txt" | xargs rm   # delete found files
```

```bash copy
cat files.txt | xargs -n 1 process   # process one at a time
```

```bash copy
find /path -name "*.log" -print0 | xargs -0 gzip   # handle spaces
```

**Screen:**

```bash copy
screen   # start session
```

```bash copy
screen -S name   # start named session
```

```bash copy
screen -ls   # list sessions
```

```bash copy
screen -r name   # reattach to session
```

**tmux:**

```bash copy
tmux   # start session
```

```bash copy
tmux new -s name   # start named session
```

```bash copy
tmux ls   # list sessions
```

```bash copy
tmux attach -t name   # attach to session
```

**Checksums:**

```bash copy
md5sum file   # MD5 checksum
```

```bash copy
sha256sum file   # SHA256 checksum
```

```bash copy
sha256sum -c checksums.txt   # verify checksums
```

</div>

</details>

---

<details>
<summary><strong>18. Quick Reference</strong></summary>

<div style="margin-left: 16px; margin-right: 16px; margin-top: 8px; margin-bottom: 8px;">

**Key Concepts:**
- `tar` combines files, compression (gzip/bzip2/xz) reduces size
- `find` searches filesystem by name, size, time, permissions
- `locate` is faster but uses pre-built database
- Background jobs with `&` continue after shell closes with `nohup`
- Terminal multiplexers (screen/tmux) keep sessions alive over SSH
- `xargs` builds commands from stdin
- Always use `-print0` and `-0` with find/xargs for filenames with spaces

**Compression Comparison:**

| Tool | Speed | Compression | Extension | Compress | Decompress |
|------|-------|-------------|-----------|----------|------------|
| gzip | Fast | Good | .gz | `gzip file` | `gunzip file.gz` |
| bzip2 | Medium | Better | .bz2 | `bzip2 file` | `bunzip2 file.bz2` |
| xz | Slow | Best | .xz | `xz file` | `unxz file.xz` |

**tar Quick Reference:**

| Task | Command |
|------|---------|
| Create archive | `tar -cvf archive.tar dir/` |
| Extract archive | `tar -xvf archive.tar` |
| List contents | `tar -tvf archive.tar` |
| Create gzip | `tar -czf archive.tar.gz dir/` |
| Extract gzip | `tar -xzf archive.tar.gz` |
| Create bzip2 | `tar -cjf archive.tar.bz2 dir/` |
| Create xz | `tar -cJf archive.tar.xz dir/` |
| With exclusions | `tar -czf backup.tar.gz --exclude='*.log' dir/` |

**find Quick Reference:**

| Task | Command |
|------|---------|
| By name | `find /path -name "*.txt"` |
| Case-insensitive | `find /path -iname "file"` |
| By size (> 100MB) | `find /path -size +100M` |
| By size (< 1MB) | `find /path -size -1M` |
| Modified last 7 days | `find /path -mtime -7` |
| Modified > 30 days ago | `find /path -mtime +30` |
| By type (files) | `find /path -type f` |
| By type (directories) | `find /path -type d` |
| By permissions | `find /path -perm 644` |
| Empty files | `find /path -type f -empty` |
| Delete found files | `find /path -name "*.tmp" -delete` |
| Execute on found files | `find /path -name "*.log" -exec gzip {} \;` |

**Background Jobs:**

| Command | Purpose |
|---------|---------|
| `command &` | Run in background |
| `nohup command &` | Run and survive logout |
| `jobs` | List background jobs |
| `fg %1` | Bring job 1 to foreground |
| `bg %1` | Continue job 1 in background |
| `Ctrl+Z` | Suspend current job |
| `disown` | Detach job from shell |

**tmux vs screen:**

| Feature | screen | tmux |
|---------|--------|------|
| Start session | `screen` | `tmux` |
| Named session | `screen -S name` | `tmux new -s name` |
| Detach | `Ctrl+A D` | `Ctrl+B D` |
| List sessions | `screen -ls` | `tmux ls` |
| Reattach | `screen -r` | `tmux attach -t name` |
| Split panes | Limited | Excellent |
| Active development | No | Yes |

**xargs Patterns:**

| Pattern | Purpose |
|---------|---------|
| `cmd \| xargs rm` | Delete found items |
| `cmd \| xargs -n 1` | Process one at a time |
| `cmd \| xargs -P 4` | Use 4 parallel processes |
| `cmd -print0 \| xargs -0` | Handle spaces in filenames |
| `cmd \| xargs -I {}` | Replace string placeholder |

**Disk Usage Commands:**

| Command | Purpose |
|---------|---------|
| `du -sh /path` | Total size of directory |
| `du -h --max-depth=1 /path` | Size of subdirectories |
| `du -h /path \| sort -rh \| head -20` | Top 20 largest |
| `ncdu /path` | Interactive exploration |

**Backup Script Template:**

```bash
#!/bin/bash
BACKUP_DIR="/backups"
DATE=$(date +%Y%m%d)
SOURCE="/data"

# Create compressed backup
tar -czf $BACKUP_DIR/backup_$DATE.tar.gz \
  --exclude='*.log' \
  --exclude='*.tmp' \
  $SOURCE

# Keep only last 7 days
find $BACKUP_DIR -name "backup_*.tar.gz" -mtime +7 -delete

# Verify
ls -lh $BACKUP_DIR/
```

**Common find Patterns:**

| Use Case | Command |
|----------|---------|
| Large files | `find / -type f -size +100M -exec ls -lh {} \;` |
| Old logs | `find /var/log -name "*.log" -mtime +30` |
| Empty files | `find /path -type f -empty -delete` |
| Files by user | `find /path -user username` |
| SUID files | `find / -perm -4000` |
| Writable by others | `find /path -perm -002` |

**Compression Level Guide:**

| Need | Tool | Level | Command |
|------|------|-------|---------|
| Fast backup | gzip | -1 | `tar -cz1f backup.tar.gz dir/` |
| Balanced | gzip | default | `tar -czf backup.tar.gz dir/` |
| Best compression | xz | default | `tar -cJf backup.tar.xz dir/` |
| Legacy compatibility | gzip | default | `tar -czf backup.tar.gz dir/` |

**What's Next:**
You now have a complete Linux toolkit! These utilities complement the core 11 files, giving you every tool needed for DevOps work. Practice these commands in real scenarios to build muscle memory.

</div>

</details>

---